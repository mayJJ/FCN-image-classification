{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhadmin/imageclassify/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 43s - loss: 0.2943 - acc: 0.9120 - val_loss: 0.0729 - val_acc: 0.9772\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 43s - loss: 0.1205 - acc: 0.9640 - val_loss: 0.0574 - val_acc: 0.9813\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 43s - loss: 0.0912 - acc: 0.9721 - val_loss: 0.0442 - val_acc: 0.9842\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 43s - loss: 0.0785 - acc: 0.9760 - val_loss: 0.0405 - val_acc: 0.9867\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 43s - loss: 0.0680 - acc: 0.9789 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 44s - loss: 0.0611 - acc: 0.9814 - val_loss: 0.0369 - val_acc: 0.9876\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 44s - loss: 0.0560 - acc: 0.9826 - val_loss: 0.0342 - val_acc: 0.9879\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 72s - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0337 - val_acc: 0.9886\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 121s - loss: 0.0463 - acc: 0.9847 - val_loss: 0.0358 - val_acc: 0.9880\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 131s - loss: 0.0407 - acc: 0.9868 - val_loss: 0.0344 - val_acc: 0.9881\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 130s - loss: 0.0407 - acc: 0.9866 - val_loss: 0.0337 - val_acc: 0.9889\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 130s - loss: 0.0366 - acc: 0.9887 - val_loss: 0.0352 - val_acc: 0.9888\n",
      "Saved trained model at /home/lhadmin/imageclassify/app/saved_models/keras_mnist_train_model_batch_size_64.h5 \n",
      "Test loss: 0.03517873102345111\n",
      "Test accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = \"keras_mnist_train_model_batch_size_64.h5\"\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data('/home/lhadmin/imageclassify/app/mnist.npz')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test)\n",
    "         )\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 119s - loss: 0.4550 - acc: 0.8647 - val_loss: 0.1508 - val_acc: 0.9566\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 118s - loss: 0.1961 - acc: 0.9431 - val_loss: 0.1030 - val_acc: 0.9706\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 119s - loss: 0.1497 - acc: 0.9559 - val_loss: 0.0844 - val_acc: 0.9732\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 118s - loss: 0.1276 - acc: 0.9628 - val_loss: 0.0692 - val_acc: 0.9792\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 119s - loss: 0.1108 - acc: 0.9678 - val_loss: 0.0627 - val_acc: 0.9803\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 119s - loss: 0.1001 - acc: 0.9708 - val_loss: 0.0566 - val_acc: 0.9825\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 110s - loss: 0.0940 - acc: 0.9726 - val_loss: 0.0506 - val_acc: 0.9839\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 86s - loss: 0.0856 - acc: 0.9743 - val_loss: 0.0522 - val_acc: 0.9824\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 86s - loss: 0.0796 - acc: 0.9772 - val_loss: 0.0468 - val_acc: 0.9837\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 87s - loss: 0.0775 - acc: 0.9773 - val_loss: 0.0456 - val_acc: 0.9844\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 108s - loss: 0.0722 - acc: 0.9786 - val_loss: 0.0444 - val_acc: 0.9848\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 87s - loss: 0.0687 - acc: 0.9799 - val_loss: 0.0435 - val_acc: 0.9852\n",
      "Test loss: 0.043502395467623134\n",
      "Test accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data('/home/lhadmin/imageclassify/app/mnist.npz')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 79s - loss: 0.5633 - acc: 0.8353 - val_loss: 0.2103 - val_acc: 0.9394\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 79s - loss: 0.2545 - acc: 0.9259 - val_loss: 0.1350 - val_acc: 0.9607\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 77s - loss: 0.1932 - acc: 0.9425 - val_loss: 0.1079 - val_acc: 0.9673\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 77s - loss: 0.1627 - acc: 0.9530 - val_loss: 0.0906 - val_acc: 0.9714\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 75s - loss: 0.1421 - acc: 0.9590 - val_loss: 0.0775 - val_acc: 0.9760\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 77s - loss: 0.1275 - acc: 0.9633 - val_loss: 0.0739 - val_acc: 0.9767\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 76s - loss: 0.1168 - acc: 0.9659 - val_loss: 0.0634 - val_acc: 0.9794\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 75s - loss: 0.1063 - acc: 0.9684 - val_loss: 0.0589 - val_acc: 0.9813\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 76s - loss: 0.0991 - acc: 0.9714 - val_loss: 0.0567 - val_acc: 0.9808\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 75s - loss: 0.0914 - acc: 0.9731 - val_loss: 0.0532 - val_acc: 0.9816\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 76s - loss: 0.0895 - acc: 0.9742 - val_loss: 0.0508 - val_acc: 0.9827\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 76s - loss: 0.0849 - acc: 0.9750 - val_loss: 0.0506 - val_acc: 0.9822\n",
      "Test loss: 0.05061755746328272\n",
      "Test accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data('/home/lhadmin/imageclassify/app/mnist.npz')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epochs_size=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 74s - loss: 0.7074 - acc: 0.7971 - val_loss: 0.2471 - val_acc: 0.9312\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 72s - loss: 0.2948 - acc: 0.9138 - val_loss: 0.1618 - val_acc: 0.9542\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 71s - loss: 0.2174 - acc: 0.9368 - val_loss: 0.1404 - val_acc: 0.9573\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 72s - loss: 0.1816 - acc: 0.9470 - val_loss: 0.1026 - val_acc: 0.9703\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 73s - loss: 0.1547 - acc: 0.9550 - val_loss: 0.0897 - val_acc: 0.9726\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 72s - loss: 0.1396 - acc: 0.9594 - val_loss: 0.0816 - val_acc: 0.9745\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 74s - loss: 0.1273 - acc: 0.9633 - val_loss: 0.0792 - val_acc: 0.9742\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 73s - loss: 0.1185 - acc: 0.9654 - val_loss: 0.0702 - val_acc: 0.9784\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 72s - loss: 0.1081 - acc: 0.9686 - val_loss: 0.0680 - val_acc: 0.9793\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 74s - loss: 0.1035 - acc: 0.9697 - val_loss: 0.0628 - val_acc: 0.9800\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 73s - loss: 0.0968 - acc: 0.9719 - val_loss: 0.0570 - val_acc: 0.9817\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 73s - loss: 0.0918 - acc: 0.9728 - val_loss: 0.0550 - val_acc: 0.9823\n",
      "Test loss: 0.05498370573730208\n",
      "Test accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data('/home/lhadmin/imageclassify/app/mnist.npz')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
